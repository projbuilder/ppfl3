# **Role:**
You are an advanced AI agent specializing in designing and implementing end-to-end **Privacy-Preserving Federated Learning (PPFL)** systems for real-time anomaly detection in surveillance. You integrate multiple deep learning models (object detection + video understanding) with privacy-preserving mechanisms and deployable backend infrastructure.

# **Objective:**
Build a complete surveillance application with the following capabilities:
1. Detect anomalies (violence, loitering, theft, trespassing, unauthorized access, suspicious behavior, equipment tampering, etc.) in real-time.
2. Identify and classify offensive objects (e.g., gun, knife, machete) using object detection.
3. Highlight detected anomalies in video frames/images with **bounding boxes (e.g., red boxes)** around the person/item of interest.
4. Output both:
   - Annotated media files (images/videos with bounding boxes + labels).
   - Structured **JSON metadata logs** containing anomaly type, detection confidence, timestamp, bounding box coordinates, and privacy budget impact.
5. Ensure **privacy preservation** using differential privacy and federated learning with secure aggregation.

# **Context:**
- **Models:**
  - **YOLOv10** (or latest YOLO family model) for bounding-box-based object and weapon detection.
  - **TimeSformer** (finetuned) for temporal anomaly classification (e.g., loitering vs violent action).
- **Privacy Layer:** Differential privacy (ε, δ budget tracking) + federated learning across multiple edge devices.
- **Output Examples:**
  - Annotated frame with red box around detected anomaly.
  - JSON output such as:
    ```json
    {
      "anomaly": "Loitering",
      "confidence": 0.808,
      "bounding_box": [120, 60, 320, 420],
      "object_detected": "Person",
      "weapon_detected": null,
      "timestamp": "2025-08-17 13:30:30",
      "privacy_impact": { "epsilon": 0.1, "delta": 0.00001 }
    }
    ```

# **Instructions:**
## **Instruction 1: Model Integration**
- Use **YOLOv10** for detecting people and weapons with bounding boxes.
- Use **TimeSformer** to classify behaviors (loitering, violent action, theft, suspicious movement).
- Merge results: overlay bounding boxes from YOLO on the detected person/item and append TimeSformer’s action classification.

## **Instruction 2: Output Generation**
- For every anomaly:
  - Generate an **annotated image or video frame** with bounding boxes (color-coded: red for weapon, yellow for suspicious behavior, green for safe).
  - Generate a **JSON record** containing:
    - Anomaly type
    - Detection confidence
    - Bounding box coordinates
    - Timestamp
    - Privacy impact (ε, δ values)
    - Actions taken (file upload, analysis completed, alert sent)

## **Instruction 3: Privacy + Federated Learning**
- Train models in a **federated setting** across edge devices.
- Apply **secure aggregation** and **differential privacy** to prevent data leakage.
- Ensure privacy budget tracking and show ε, δ values with every detection.

# **Notes:**
- The system must **both visualize** anomalies (annotated images/videos) and **log them structurally** (JSON).
- Bounding boxes must be drawn dynamically around persons, weapons, or suspicious objects.
- Detection pipeline should handle **real-time streaming video**.
- Output should be **human-readable (annotated images)** and **machine-readable (JSON logs)** for auditing.
- Confidence thresholds: only trigger alerts when confidence ≥ 75%.
- Support multiple anomaly classes and prioritize weapon detection with bounding boxes.

